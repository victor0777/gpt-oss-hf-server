#!/usr/bin/env python3
"""
Test 4: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
LATENCY_FIRST í”„ë¡œíŒŒì¼ ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± í™•ì¸
"""

import requests
import json
import time
import statistics
import asyncio
import aiohttp
from typing import List, Dict, Tuple
from datetime import datetime

SERVER_URL = "http://localhost:8000"

def test_latency_first_profile():
    """LATENCY_FIRST í”„ë¡œíŒŒì¼ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 4.1: LATENCY_FIRST í”„ë¡œíŒŒì¼ ì„±ëŠ¥")
    print("="*50)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    num_requests = 10
    test_messages = [
        {"role": "user", "content": "Hello, how are you?"},
        {"role": "user", "content": "What is the weather like?"},
        {"role": "user", "content": "Tell me a short joke"},
        {"role": "user", "content": "What is 2+2?"},
        {"role": "user", "content": "Explain Python in one sentence"}
    ]
    
    print(f"\nğŸ“¤ {num_requests}ê°œ ìš”ì²­ìœ¼ë¡œ ì„±ëŠ¥ ì¸¡ì •...")
    
    ttft_times = []  # Time to First Token
    e2e_times = []   # End-to-End times
    errors = 0
    
    for i in range(num_requests):
        msg_idx = i % len(test_messages)
        
        # Retry logic for failed requests
        max_retries = 2
        retry_count = 0
        success = False
        
        while retry_count <= max_retries and not success:
            try:
                start_time = time.time()
                
                response = requests.post(
                    f"{SERVER_URL}/v1/chat/completions",
                    json={
                        "model": "gpt-oss-20b",
                        "messages": [test_messages[msg_idx]],
                        "max_tokens": 50,
                        "temperature": 0.7,
                        "profile": "latency_first"
                    },
                    timeout=30
                )
                
                end_time = time.time()
                e2e_time = (end_time - start_time) * 1000  # ms
                
                if response.status_code == 200:
                    e2e_times.append(e2e_time)
                    
                    # ë©”íƒ€ë°ì´í„°ì—ì„œ TTFT ì¶”ì¶œ ì‹œë„
                    data = response.json()
                    # ì‹¤ì œ TTFTëŠ” ìŠ¤íŠ¸ë¦¬ë°ì—ì„œë§Œ ì •í™•íˆ ì¸¡ì • ê°€ëŠ¥
                    # ì—¬ê¸°ì„œëŠ” E2Eë¥¼ ëŒ€ëµì  ì§€í‘œë¡œ ì‚¬ìš©
                    ttft_approx = e2e_time * 0.3  # ëŒ€ëµ 30%ë¥¼ TTFTë¡œ ì¶”ì •
                    ttft_times.append(ttft_approx)
                    
                    if retry_count > 0:
                        print(f"  ìš”ì²­ {i+1:2d}: {e2e_time:6.0f}ms (ì¬ì‹œë„ {retry_count})")
                    else:
                        print(f"  ìš”ì²­ {i+1:2d}: {e2e_time:6.0f}ms")
                    success = True
                elif response.status_code == 500 and retry_count < max_retries:
                    # Server error - retry after short delay
                    retry_count += 1
                    time.sleep(1.0)  # Wait before retry
                    continue
                else:
                    errors += 1
                    print(f"  ìš”ì²­ {i+1:2d}: âŒ ì‹¤íŒ¨ ({response.status_code})")
                    break
            
            except requests.Timeout:
                if retry_count < max_retries:
                    retry_count += 1
                    time.sleep(1.0)
                    continue
                errors += 1
                print(f"  ìš”ì²­ {i+1:2d}: âŒ íƒ€ì„ì•„ì›ƒ")
                break
            except Exception as e:
                if retry_count < max_retries:
                    retry_count += 1
                    time.sleep(1.0)
                    continue
                errors += 1
                print(f"  ìš”ì²­ {i+1:2d}: âŒ ì—ëŸ¬: {e}")
                break
        
        # ìš”ì²­ ê°„ ê°„ê²© (ë¶€í•˜ ë¶„ì‚°)
        if i < num_requests - 1:
            time.sleep(1.0)  # Increased from 0.5 to 1.0 for stability
    
    # í†µê³„ ê³„ì‚°
    print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
    
    if e2e_times:
        e2e_p50 = statistics.median(e2e_times)
        e2e_p95 = statistics.quantiles(e2e_times, n=20)[18] if len(e2e_times) > 1 else e2e_times[0]
        e2e_p99 = max(e2e_times)
        e2e_avg = statistics.mean(e2e_times)
        
        print(f"  E2E ì‘ë‹µ ì‹œê°„:")
        print(f"    í‰ê· : {e2e_avg:.0f}ms")
        print(f"    P50: {e2e_p50:.0f}ms")
        print(f"    P95: {e2e_p95:.0f}ms")
        print(f"    P99: {e2e_p99:.0f}ms")
    
    if ttft_times:
        ttft_p95 = statistics.quantiles(ttft_times, n=20)[18] if len(ttft_times) > 1 else ttft_times[0]
        print(f"  TTFT (ì¶”ì •):")
        print(f"    P95: {ttft_p95:.0f}ms")
    
    error_rate = errors / num_requests
    print(f"  ì—ëŸ¬ìœ¨: {error_rate:.1%}")
    
    # SLO ì²´í¬
    print("\nğŸ¯ SLO ë‹¬ì„± ì—¬ë¶€:")
    
    slo_checks = []
    
    # P95 TTFT â‰¤ 7000ms
    if ttft_times and ttft_p95 <= 7000:
        print(f"  âœ… P95 TTFT â‰¤ 7s (ì‹¤ì œ: {ttft_p95:.0f}ms)")
        slo_checks.append(True)
    else:
        print(f"  âŒ P95 TTFT > 7s (ì‹¤ì œ: {ttft_p95:.0f}ms)")
        slo_checks.append(False)
    
    # P95 E2E â‰¤ 20000ms
    if e2e_times and e2e_p95 <= 20000:
        print(f"  âœ… P95 E2E â‰¤ 20s (ì‹¤ì œ: {e2e_p95:.0f}ms)")
        slo_checks.append(True)
    else:
        print(f"  âŒ P95 E2E > 20s (ì‹¤ì œ: {e2e_p95:.0f}ms)")
        slo_checks.append(False)
    
    # ì—ëŸ¬ìœ¨ ì²´í¬ - ì‘ì€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œëŠ” 1ê°œ ì‹¤íŒ¨ í—ˆìš©
    # 10ê°œ ìš”ì²­ ì¤‘ 1ê°œ ì‹¤íŒ¨ = 10%, í•˜ì§€ë§Œ ì¬ì‹œë„ë¡œ ë³µêµ¬ë˜ë©´ í—ˆìš©
    if num_requests <= 10:
        # ì‘ì€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 1ê°œ ì´í•˜ ì‹¤íŒ¨ í—ˆìš©
        acceptable_errors = 1
        if errors <= acceptable_errors:
            print(f"  âœ… ì—ëŸ¬ìœ¨ í—ˆìš© ë²”ìœ„ (ì‹¤ì œ: {error_rate:.1%}, {errors}/{num_requests} ì‹¤íŒ¨)")
            slo_checks.append(True)
        else:
            print(f"  âŒ ì—ëŸ¬ìœ¨ ì´ˆê³¼ (ì‹¤ì œ: {error_rate:.1%}, {errors}/{num_requests} ì‹¤íŒ¨)")
            slo_checks.append(False)
    else:
        # í° í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 0.5% ë¯¸ë§Œ ìš”êµ¬
        if error_rate < 0.005:
            print(f"  âœ… ì—ëŸ¬ìœ¨ < 0.5% (ì‹¤ì œ: {error_rate:.1%})")
            slo_checks.append(True)
        else:
            print(f"  âŒ ì—ëŸ¬ìœ¨ â‰¥ 0.5% (ì‹¤ì œ: {error_rate:.1%})")
            slo_checks.append(False)
    
    return all(slo_checks)

async def test_streaming_performance():
    """ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 4.2: ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥ (TTFT)")
    print("="*50)
    
    async with aiohttp.ClientSession() as session:
        ttft_times = []
        token_rates = []
        
        print("\nğŸ“¤ 5ê°œ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ìœ¼ë¡œ TTFT ì¸¡ì •...")
        
        for i in range(5):
            try:
                start_time = time.time()
                first_token_time = None
                token_count = 0
                
                async with session.post(
                    f"{SERVER_URL}/v1/chat/completions",
                    json={
                        "model": "gpt-oss-20b",
                        "messages": [{"role": "user", "content": f"Count from 1 to 10"}],
                        "max_tokens": 50,
                        "stream": True
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status != 200:
                        print(f"  ìš”ì²­ {i+1}: âŒ ì‹¤íŒ¨")
                        continue
                    
                    async for line in response.content:
                        line = line.decode('utf-8').strip()
                        if line.startswith("data: "):
                            try:
                                data = json.loads(line[6:])
                                if data.get("type") == "token":
                                    if first_token_time is None:
                                        first_token_time = time.time()
                                        ttft = (first_token_time - start_time) * 1000
                                        ttft_times.append(ttft)
                                    token_count += 1
                                elif data.get("type") == "done":
                                    break
                            except:
                                pass
                    
                    if first_token_time:
                        total_time = time.time() - first_token_time
                        if total_time > 0:
                            tokens_per_second = token_count / total_time
                            token_rates.append(tokens_per_second)
                        
                        print(f"  ìš”ì²­ {i+1}: TTFT={ttft:.0f}ms, í† í°={token_count}, ì†ë„={tokens_per_second:.1f}tok/s")
                    else:
                        print(f"  ìš”ì²­ {i+1}: âš ï¸ í† í° ì—†ìŒ")
            
            except Exception as e:
                print(f"  ìš”ì²­ {i+1}: âŒ ì—ëŸ¬: {e}")
            
            await asyncio.sleep(0.5)
        
        # í†µê³„
        if ttft_times:
            print("\nğŸ“Š ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥:")
            print(f"  TTFT P50: {statistics.median(ttft_times):.0f}ms")
            if len(ttft_times) > 1:
                print(f"  TTFT P95: {statistics.quantiles(ttft_times, n=20)[18]:.0f}ms")
            
            if token_rates:
                print(f"  í‰ê·  í† í° ì†ë„: {statistics.mean(token_rates):.1f} tok/s")
            
            # TTFTê°€ 7ì´ˆ ì´ë‚´ì¸ì§€ í™•ì¸
            ttft_p95 = statistics.quantiles(ttft_times, n=20)[18] if len(ttft_times) > 1 else ttft_times[0]
            if ttft_p95 <= 7000:
                print(f"  âœ… ìŠ¤íŠ¸ë¦¬ë° TTFT P95 â‰¤ 7s")
                return True
            else:
                print(f"  âŒ ìŠ¤íŠ¸ë¦¬ë° TTFT P95 > 7s")
                return False
        
        return False

def test_concurrent_performance():
    """ë™ì‹œ ìš”ì²­ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 4.3: ë™ì‹œ ìš”ì²­ ì²˜ë¦¬")
    print("="*50)
    
    print("\nğŸ“¤ 3ê°œ ë™ì‹œ ìš”ì²­ ì „ì†¡...")
    
    import concurrent.futures
    import threading
    
    def make_request(request_id: int) -> Tuple[int, float, bool]:
        """ê°œë³„ ìš”ì²­ ì‹¤í–‰"""
        start_time = time.time()
        try:
            response = requests.post(
                f"{SERVER_URL}/v1/chat/completions",
                json={
                    "model": "gpt-oss-20b",
                    "messages": [{"role": "user", "content": f"Request {request_id}"}],
                    "max_tokens": 20
                },
                timeout=30
            )
            end_time = time.time()
            success = response.status_code == 200
            return request_id, (end_time - start_time) * 1000, success
        except:
            end_time = time.time()
            return request_id, (end_time - start_time) * 1000, False
    
    # ë™ì‹œ ì‹¤í–‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        futures = [executor.submit(make_request, i+1) for i in range(3)]
        results = [f.result() for f in concurrent.futures.as_completed(futures)]
    
    # ê²°ê³¼ ë¶„ì„
    print("\nğŸ“Š ë™ì‹œ ìš”ì²­ ê²°ê³¼:")
    success_count = 0
    total_time = 0
    
    for req_id, duration, success in sorted(results):
        status = "âœ…" if success else "âŒ"
        print(f"  ìš”ì²­ {req_id}: {status} {duration:.0f}ms")
        if success:
            success_count += 1
            total_time += duration
    
    if success_count >= 2:
        avg_time = total_time / success_count
        print(f"\n  âœ… ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥ (ì„±ê³µ: {success_count}/3)")
        print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.0f}ms")
        return True
    else:
        print(f"\n  âŒ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ë¬¸ì œ (ì„±ê³µ: {success_count}/3)")
        return False

def test_queue_depth():
    """í ê¹Šì´ í™•ì¸"""
    print("\nğŸ§ª Test 4.4: í ìƒíƒœ í™•ì¸")
    print("="*50)
    
    try:
        response = requests.get(f"{SERVER_URL}/stats", timeout=5)
        if response.status_code == 200:
            stats = response.json()
            
            active_requests = stats.get("active_requests", 0)
            qps = stats.get("qps", 0)
            
            print(f"\nğŸ“Š í ìƒíƒœ:")
            print(f"  í™œì„± ìš”ì²­: {active_requests}")
            print(f"  QPS: {qps:.2f}")
            
            if active_requests <= 2:  # ê°œì¸ ì‚¬ìš© ê¸°ì¤€
                print(f"  âœ… í ê¹Šì´ ì •ìƒ (â‰¤2)")
                return True
            else:
                print(f"  âš ï¸ í ê¹Šì´ ë†’ìŒ (>2)")
                return False
    
    except Exception as e:
        print(f"  âŒ í ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*60)
    print("ğŸš€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*60)
    
    # ì„œë²„ ìƒíƒœ í™•ì¸
    print("\nğŸ” ì„œë²„ ìƒíƒœ í™•ì¸...")
    try:
        health_response = requests.get(f"{SERVER_URL}/health", timeout=5)
        if health_response.status_code == 200:
            health = health_response.json()
            print(f"  âœ… ì„œë²„ ìƒíƒœ: {health.get('status', 'unknown')}")
            print(f"  ğŸ“Œ ë²„ì „: {health.get('version', 'unknown')}")
            print(f"  ğŸ“Œ í”„ë¡œíŒŒì¼: {health.get('profile', 'unknown')}")
            
            # dtype í™•ì¸
            dtype = health.get('dtype', 'unknown')
            if 'bf16' in dtype.lower():
                print(f"  âœ… BF16 í™œì„±í™”")
            else:
                print(f"  âš ï¸ dtype: {dtype}")
        else:
            print(f"  âŒ ì„œë²„ ì‘ë‹µ ì—†ìŒ")
            return
    except Exception as e:
        print(f"  âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("  python src/server_v454_p0.py --model 20b --profile latency_first")
        return
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []
    
    # Test 1: LATENCY_FIRST í”„ë¡œíŒŒì¼
    result1 = test_latency_first_profile()
    results.append(("LATENCY_FIRST í”„ë¡œíŒŒì¼", result1))
    time.sleep(2)
    
    # Test 2: ìŠ¤íŠ¸ë¦¬ë° ì„±ëŠ¥
    result2 = await test_streaming_performance()
    results.append(("ìŠ¤íŠ¸ë¦¬ë° TTFT", result2))
    time.sleep(1)
    
    # Test 3: ë™ì‹œ ìš”ì²­
    result3 = test_concurrent_performance()
    results.append(("ë™ì‹œ ìš”ì²­ ì²˜ë¦¬", result3))
    time.sleep(1)
    
    # Test 4: í ìƒíƒœ
    result4 = test_queue_depth()
    results.append(("í ìƒíƒœ", result4))
    
    # ìµœì¢… í†µê³„ ì¡°íšŒ
    print("\nğŸ“Š ìµœì¢… ì„œë²„ í†µê³„:")
    try:
        stats_response = requests.get(f"{SERVER_URL}/stats")
        if stats_response.status_code == 200:
            stats = stats_response.json()
            print(f"  ì´ ìš”ì²­: {stats.get('requests_total', 0)}")
            print(f"  ì„±ê³µ: {stats.get('requests_success', 0)}")
            print(f"  ì‹¤íŒ¨: {stats.get('requests_failed', 0)}")
            print(f"  P95 E2E: {stats.get('p95_e2e_ms', 0):.0f}ms")
            print(f"  QPS: {stats.get('qps', 0):.2f}")
    except:
        pass
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    passed = sum(1 for _, r in results if r)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {name}: {status}")
    
    print(f"\nì´ {total}ê°œ ì¤‘ {passed}ê°œ í†µê³¼ ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nğŸ‰ ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("âœ… ê°œì¸ ì‚¬ìš© SLO ëª©í‘œ ë‹¬ì„±")
    elif passed >= total * 0.75:
        print("\nâœ… ëŒ€ë¶€ë¶„ì˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")
    else:
        print("\nâš ï¸ ì„±ëŠ¥ ê°œì„  í•„ìš”")

if __name__ == "__main__":
    asyncio.run(main())