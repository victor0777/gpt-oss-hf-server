#!/usr/bin/env python3
"""
Test 3: PR-OBS01 - λ¨λΈ νƒκΉ… ν…μ¤νΈ
λ¨λ“  μ—”λ“ν¬μΈνΈμ—μ„ λ¨λΈ μ •λ³΄κ°€ νƒκΉ…λλ”μ§€ ν™•μΈ
"""

import requests
import json
import time
from typing import Dict, List

SERVER_URL = "http://localhost:8000"

def test_health_endpoint():
    """Health μ—”λ“ν¬μΈνΈ λ¨λΈ νƒκΉ… ν…μ¤νΈ"""
    print("\nπ§ Test 3.1: /health μ—”λ“ν¬μΈνΈ νƒκΉ…")
    print("="*50)
    
    try:
        response = requests.get(f"{SERVER_URL}/health", timeout=5)
        
        if response.status_code != 200:
            print(f"  β Health μ”μ²­ μ‹¤ν¨: {response.status_code}")
            return False
        
        data = response.json()
        print("\nπ“ Health μ‘λ‹µ:")
        print(f"  μƒνƒ: {data.get('status', 'unknown')}")
        print(f"  λ²„μ „: {data.get('version', 'unknown')}")
        print(f"  dtype: {data.get('dtype', 'unknown')}")
        print(f"  ν”„λ΅νμΌ: {data.get('profile', 'unknown')}")
        
        # λ¨λΈ μ •λ³΄ ν™•μΈ
        model_info = data.get('model', {})
        if not model_info:
            print("\n  β λ¨λΈ μ •λ³΄ μ—†μ")
            return False
        
        print("\nπ“ λ¨λΈ νƒκΉ… μ •λ³΄:")
        required_tags = ["model_id", "model_size", "dtype", "gpu_mode", "prompt_version"]
        missing_tags = []
        
        for tag in required_tags:
            value = model_info.get(tag)
            if value:
                print(f"  β… {tag}: {value}")
            else:
                print(f"  β {tag}: λ„λ½")
                missing_tags.append(tag)
        
        if not missing_tags:
            print("\n  β… λ¨λ“  ν•„μ νƒκ·Έ μ΅΄μ¬")
            return True
        else:
            print(f"\n  β λ„λ½λ νƒκ·Έ: {missing_tags}")
            return False
    
    except Exception as e:
        print(f"  β Health μ—”λ“ν¬μΈνΈ μ—λ¬: {e}")
        return False

def test_stats_endpoint():
    """Stats μ—”λ“ν¬μΈνΈ λ¨λΈ νƒκΉ… ν…μ¤νΈ"""
    print("\nπ§ Test 3.2: /stats μ—”λ“ν¬μΈνΈ νƒκΉ…")
    print("="*50)
    
    # λ¨Όμ € μ”μ²­μ„ ν•λ‚ μƒμ„±
    print("\nπ“¤ ν…μ¤νΈ μ”μ²­ μƒμ„±...")
    try:
        test_response = requests.post(
            f"{SERVER_URL}/v1/chat/completions",
            json={
                "model": "gpt-oss-20b",
                "messages": [{"role": "user", "content": "Test for stats"}],
                "max_tokens": 10
            },
            timeout=30
        )
        print(f"  ν…μ¤νΈ μ”μ²­ μƒνƒ: {test_response.status_code}")
    except:
        print("  β οΈ ν…μ¤νΈ μ”μ²­ μ‹¤ν¨ (κ³„μ† μ§„ν–‰)")
    
    time.sleep(1)
    
    # Stats μ΅°ν
    try:
        response = requests.get(f"{SERVER_URL}/stats", timeout=5)
        
        if response.status_code != 200:
            print(f"  β Stats μ”μ²­ μ‹¤ν¨: {response.status_code}")
            return False
        
        data = response.json()
        
        print("\nπ“ Stats κΈ°λ³Έ μ •λ³΄:")
        print(f"  μ΄ μ”μ²­: {data.get('requests_total', 0)}")
        print(f"  μ„±κ³µ: {data.get('requests_success', 0)}")
        print(f"  μ‹¤ν¨: {data.get('requests_failed', 0)}")
        print(f"  QPS: {data.get('qps', 0)}")
        
        # model_info ν™•μΈ
        model_info = data.get('model_info', {})
        if model_info:
            print("\nπ“ λ¨λΈ μ •λ³΄:")
            for key, value in model_info.items():
                print(f"  {key}: {value}")
            print("  β… model_info μ΅΄μ¬")
        else:
            print("  β οΈ model_info μ—†μ")
        
        # model_metrics ν™•μΈ
        model_metrics = data.get('model_metrics', {})
        if model_metrics:
            print("\nπ“ λ¨λΈλ³„ λ©”νΈλ¦­:")
            for key, metrics in model_metrics.items():
                print(f"  {key}:")
                print(f"    - μ΄ μ”μ²­: {metrics.get('total', 0)}")
                print(f"    - μ„±κ³µ: {metrics.get('success', 0)}")
                print(f"    - μ‹¤ν¨: {metrics.get('failed', 0)}")
                print(f"    - μ·¨μ†: {metrics.get('cancelled', 0)}")
            print("  β… model_metrics μ΅΄μ¬")
        else:
            print("  β οΈ model_metrics μ—†μ")
        
        # prompt_metrics ν™•μΈ
        prompt_metrics = data.get('prompt_metrics', {})
        if prompt_metrics:
            print("\nπ“ ν”„λ΅¬ν”„νΈ λ©”νΈλ¦­:")
            print(f"  μΊμ‹ ννΈ: {prompt_metrics.get('cache_hits', 0)}")
            print(f"  μΊμ‹ λ―Έμ¤: {prompt_metrics.get('cache_misses', 0)}")
            print(f"  μΊμ‹ ννΈμ¨: {prompt_metrics.get('cache_hit_rate', 0):.1%}")
            print(f"  μΊμ‹ ν¬κΈ°: {prompt_metrics.get('cache_size', 0)}")
            print("  β… prompt_metrics μ΅΄μ¬")
        
        # μ „μ²΄ ν‰κ°€
        has_model_info = bool(model_info)
        has_model_metrics = bool(model_metrics)
        
        if has_model_info or has_model_metrics:
            print("\n  β… Stats μ—”λ“ν¬μΈνΈ νƒκΉ… ν™•μΈ")
            return True
        else:
            print("\n  β Stats μ—”λ“ν¬μΈνΈ νƒκΉ… λ¶€μ΅±")
            return False
    
    except Exception as e:
        print(f"  β Stats μ—”λ“ν¬μΈνΈ μ—λ¬: {e}")
        return False

def test_metrics_endpoint():
    """Prometheus λ©”νΈλ¦­ μ—”λ“ν¬μΈνΈ ν…μ¤νΈ"""
    print("\nπ§ Test 3.3: /metrics μ—”λ“ν¬μΈνΈ (Prometheus)")
    print("="*50)
    
    try:
        response = requests.get(f"{SERVER_URL}/metrics", timeout=5)
        
        if response.status_code != 200:
            print(f"  β Metrics μ”μ²­ μ‹¤ν¨: {response.status_code}")
            return False
        
        metrics_text = response.text
        
        print("\nπ“ Prometheus λ©”νΈλ¦­ λ¶„μ„:")
        
        # μ£Όμ” λ©”νΈλ¦­ ν™•μΈ
        metrics_found = {
            "requests_total": "requests_total" in metrics_text,
            "requests_active": "requests_active" in metrics_text,
            "stream_active": "stream_active" in metrics_text,
            "stream_cancelled_total": "stream_cancelled_total" in metrics_text,
            "model_requests_total": "model_requests_total" in metrics_text,
            "ttft_ms": "ttft_ms" in metrics_text,
            "e2e_ms": "e2e_ms" in metrics_text,
            "prompt_cache_hits": "prompt_cache_hits" in metrics_text,
            "prompt_cache_hit_rate": "prompt_cache_hit_rate" in metrics_text
        }
        
        for metric, found in metrics_found.items():
            status = "β…" if found else "β"
            print(f"  {status} {metric}")
        
        # λ¨λΈ λΌλ²¨ ν™•μΈ
        has_model_labels = False
        if 'model_id=' in metrics_text or 'model_size=' in metrics_text:
            has_model_labels = True
            print("\n  β… λ¨λΈ λΌλ²¨ ν¬ν•¨")
            
            # λΌλ²¨ μμ‹ μ¶λ ¥
            for line in metrics_text.split('\n'):
                if 'model_id=' in line and not line.startswith('#'):
                    print(f"    μμ‹: {line[:100]}...")
                    break
        else:
            print("\n  β οΈ λ¨λΈ λΌλ²¨ μ—†μ")
        
        # μ „μ²΄ ν‰κ°€
        essential_metrics = sum([
            metrics_found["requests_total"],
            metrics_found["ttft_ms"],
            metrics_found["e2e_ms"]
        ])
        
        if essential_metrics >= 2:
            print("\n  β… Prometheus λ©”νΈλ¦­ ν•μ‹ ν™•μΈ")
            return True
        else:
            print("\n  β ν•„μ λ©”νΈλ¦­ λ¶€μ΅±")
            return False
    
    except Exception as e:
        print(f"  β Metrics μ—”λ“ν¬μΈνΈ μ—λ¬: {e}")
        return False

def test_request_metadata():
    """μ”μ²­ μ‘λ‹µμ λ©”νƒ€λ°μ΄ν„° νƒκΉ… ν…μ¤νΈ"""
    print("\nπ§ Test 3.4: μ”μ²­ λ©”νƒ€λ°μ΄ν„° νƒκΉ…")
    print("="*50)
    
    try:
        print("\nπ“¤ ν…μ¤νΈ μ”μ²­ μ „μ†΅...")
        response = requests.post(
            f"{SERVER_URL}/v1/chat/completions",
            json={
                "model": "gpt-oss-20b",
                "messages": [{"role": "user", "content": "Check metadata"}],
                "max_tokens": 10,
                "temperature": 0
            },
            timeout=30
        )
        
        if response.status_code != 200:
            print(f"  β μ”μ²­ μ‹¤ν¨: {response.status_code}")
            return False
        
        data = response.json()
        metadata = data.get("metadata", {})
        
        if not metadata:
            print("  β οΈ λ©”νƒ€λ°μ΄ν„° μ—†μ (OpenAI νΈν™ λ¨λ“)")
            # OpenAI νΈν™ μ‘λ‹µ ν™•μΈ
            if "choices" in data and "usage" in data:
                print("  β… OpenAI νΈν™ ν•μ‹ ν™•μΈ")
                return True
            return False
        
        print("\nπ“ μ‘λ‹µ λ©”νƒ€λ°μ΄ν„°:")
        important_fields = [
            "prompt_version",
            "model_id", 
            "model_size",
            "dtype",
            "gpu_mode",
            "cache_key",
            "cache_hit",
            "tokens_before",
            "tokens_after",
            "request_id"
        ]
        
        found_count = 0
        for field in important_fields:
            value = metadata.get(field)
            if value is not None:
                print(f"  β… {field}: {value}")
                found_count += 1
            else:
                print(f"  β οΈ {field}: μ—†μ")
        
        if found_count >= 5:  # μµμ† 5κ° μ΄μƒ ν•„λ“
            print("\n  β… λ©”νƒ€λ°μ΄ν„° νƒκΉ… μ¶©λ¶„")
            return True
        else:
            print("\n  β λ©”νƒ€λ°μ΄ν„° νƒκΉ… λ¶€μ΅±")
            return False
    
    except Exception as e:
        print(f"  β μ”μ²­ λ©”νƒ€λ°μ΄ν„° ν…μ¤νΈ μ—λ¬: {e}")
        return False

def main():
    """λ©”μΈ ν…μ¤νΈ μ‹¤ν–‰"""
    print("\n" + "="*60)
    print("π€ PR-OBS01: λ¨λΈ νƒκΉ… ν…μ¤νΈ μ‹μ‘")
    print("="*60)
    
    # μ„λ²„ μƒνƒ ν™•μΈ
    print("\nπ” μ„λ²„ μƒνƒ ν™•μΈ...")
    try:
        health_response = requests.get(f"{SERVER_URL}/health", timeout=5)
        if health_response.status_code == 200:
            health = health_response.json()
            print(f"  β… μ„λ²„ μƒνƒ: {health.get('status', 'unknown')}")
            print(f"  π“ λ²„μ „: {health.get('version', 'unknown')}")
        else:
            print(f"  β μ„λ²„ μ‘λ‹µ μ—†μ")
            return
    except Exception as e:
        print(f"  β μ„λ²„ μ—°κ²° μ‹¤ν¨: {e}")
        print("\nπ’΅ μ„λ²„κ°€ μ‹¤ν–‰ μ¤‘μΈμ§€ ν™•μΈν•μ„Έμ”:")
        print("  python src/server_v454_p0.py --model 20b --profile latency_first")
        return
    
    # ν…μ¤νΈ μ‹¤ν–‰
    results = []
    
    # Test 1: Health μ—”λ“ν¬μΈνΈ
    result1 = test_health_endpoint()
    results.append(("Health μ—”λ“ν¬μΈνΈ", result1))
    time.sleep(1)
    
    # Test 2: Stats μ—”λ“ν¬μΈνΈ
    result2 = test_stats_endpoint()
    results.append(("Stats μ—”λ“ν¬μΈνΈ", result2))
    time.sleep(1)
    
    # Test 3: Metrics μ—”λ“ν¬μΈνΈ
    result3 = test_metrics_endpoint()
    results.append(("Metrics μ—”λ“ν¬μΈνΈ", result3))
    time.sleep(1)
    
    # Test 4: μ”μ²­ λ©”νƒ€λ°μ΄ν„°
    result4 = test_request_metadata()
    results.append(("μ”μ²­ λ©”νƒ€λ°μ΄ν„°", result4))
    
    # κ²°κ³Ό μ”μ•½
    print("\n" + "="*60)
    print("π“ ν…μ¤νΈ κ²°κ³Ό μ”μ•½")
    print("="*60)
    
    passed = sum(1 for _, r in results if r)
    total = len(results)
    
    for name, result in results:
        status = "β… PASS" if result else "β FAIL"
        print(f"  {name}: {status}")
    
    print(f"\nμ΄ {total}κ° μ¤‘ {passed}κ° ν†µκ³Ό ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nπ‰ λ¨λ“  λ¨λΈ νƒκΉ… ν…μ¤νΈ ν†µκ³Ό!")
    elif passed >= total * 0.75:
        print("\nβ… λ€λ¶€λ¶„μ λ¨λΈ νƒκΉ… ν…μ¤νΈ ν†µκ³Ό")
    else:
        print("\nβ οΈ μΌλ¶€ ν…μ¤νΈ μ‹¤ν¨. λ΅κ·Έλ¥Ό ν™•μΈν•μ„Έμ”.")

if __name__ == "__main__":
    main()